name: Marine Ministry Crawling (4x Daily)

on:
  workflow_dispatch:
    inputs:
      debug_mode:
        description: 'Enable debug mode'
        required: false
        default: 'false'
        type: choice
        options:
          - 'true'
          - 'false'

  schedule:
    - cron: '0 23 * * *'  # 08:00 KST (UTC-1ì¼ 23:00)
    - cron: '0 2 * * *'   # 11:00 KST
    - cron: '0 7 * * *'   # 16:00 KST
    - cron: '0 11 * * *'  # 20:00 KST

  push:
    branches:
      - main
    paths:
      - 'marine_ministry_crawler_final.py'
      - 'eiaa_crawler.py'
      - 'moleg_crawler.py'
      - 'ai_news_crawler.py'
      - 'upload_to_gsheet.py'
      - 'requirements.txt'
      - '.github/workflows/daily-crawling.yml'

env:
  PYTHON_VERSION: '3.11'
  TZ: 'Asia/Seoul'

jobs:
  crawl-and-upload:
    name: Crawl and Upload to Google Sheets
    runs-on: ubuntu-latest
    timeout-minutes: 60

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          pip install --upgrade pip setuptools wheel
          pip install -r requirements.txt
          playwright install chromium

      - name: Verify dependencies
        run: |
          echo "=== Python Version ==="
          python --version
          echo ""
          echo "=== Installed Packages ==="
          pip list

      - name: Create Google credentials
        env:
          GOOGLE_CREDENTIALS_JSON: ${{ secrets.GOOGLE_CREDENTIALS_JSON }}
        run: |
          echo "$GOOGLE_CREDENTIALS_JSON" | jq empty || (echo "Invalid JSON format" && exit 1)
          echo "$GOOGLE_CREDENTIALS_JSON" > gen-lang-client-0556505482-e847371ea87e.json
          chmod 600 gen-lang-client-0556505482-e847371ea87e.json
          echo "Credentials file created"

      - name: Run Marine Ministry crawler
        id: marine_crawler
        timeout-minutes: 45
        run: |
          echo "=== Starting Marine Ministry Crawler ==="
          if [ "${{ github.event.inputs.debug_mode }}" == "true" ]; then
            python -u marine_ministry_crawler_final.py
          else
            python marine_ministry_crawler_final.py
          fi
        continue-on-error: true




      - name: Run G2B crawler (Full Service)
        id: g2b_crawler
        timeout-minutes: 60
        env:
          G2B_API_KEY: ${{ secrets.G2B_API_KEY }}
        run: |
          echo "=== Starting G2B Crawler ==="
          python g2b_crawler.py
        continue-on-error: true

      - name: Run MOLEG crawler
        id: moleg_crawler
        timeout-minutes: 10
        run: |
          echo "=== Starting MOLEG Crawler ==="
          python moleg_crawler.py
        continue-on-error: true

      - name: Run AI News crawler
        id: ai_news_crawler
        timeout-minutes: 10
        env:
          NAVER_CLIENT_ID: ${{ secrets.NAVER_CLIENT_ID }}
          NAVER_CLIENT_SECRET: ${{ secrets.NAVER_CLIENT_SECRET }}
        run: |
          echo "=== Starting AI News Crawler ==="
          python ai_news_crawler.py
        continue-on-error: true

      - name: Check crawling results
        id: check_results
        run: |
          echo "=== Checking Results ==="
          
          # Check Marine Ministry results
          MARINE_CSV=$(ls marine_ministry_posts_*.csv 2>/dev/null | head -n 1)
          if [ ! -z "$MARINE_CSV" ]; then
            echo "Marine CSV: $MARINE_CSV ($(wc -l < $MARINE_CSV) lines)"
          fi



          # Check G2B results
          G2B_FILE=$(ls g2b_combined_*.csv 2>/dev/null | head -n 1)
          if [ ! -z "$G2B_FILE" ]; then
             echo "G2B CSV: $G2B_FILE ($(wc -l < $G2B_FILE) lines)"
          fi

          # Check MOLEG results
          MOLEG_CSV=$(ls moleg_data.csv 2>/dev/null | head -n 1)
          if [ ! -z "$MOLEG_CSV" ]; then
            echo "MOLEG CSV: $MOLEG_CSV ($(wc -l < $MOLEG_CSV) lines)"
          fi

          # Check AI News results
          AI_NEWS_CSV=$(ls ai_news_*.csv 2>/dev/null | head -n 1)
          if [ ! -z "$AI_NEWS_CSV" ]; then
            echo "AI News CSV: $AI_NEWS_CSV ($(wc -l < $AI_NEWS_CSV) lines)"
          fi

      - name: Upload to Google Sheets
        id: upload
        timeout-minutes: 10
        env:
          SPREADSHEET_ID: ${{ secrets.SPREADSHEET_ID }}
        run: |
          echo "=== Uploading to Google Sheets ==="
          python upload_to_gsheet.py
          echo "Upload completed"
        continue-on-error: false

      - name: Upload to Supabase
        id: upload_supabase
        timeout-minutes: 20
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        run: |
          echo "=== Uploading to Supabase ==="
          python upload_to_supabase.py
          echo "Supabase Upload completed"
        continue-on-error: false

      - name: Cleanup credentials
        if: always()
        run: |
          echo "=== Cleaning up credentials ==="
          rm -f gen-lang-client-*.json
          echo "Cleanup completed"

      - name: Upload crawling results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: crawling-results-${{ github.run_number }}
          path: |
            marine_ministry_posts_*.csv
            ai_news_*.csv
            moleg_data.csv
            *.xlsx

      - name: Upload error logs
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: error-logs-${{ github.run_number }}
          path: |
            *.log
          retention-days: 7
          if-no-files-found: ignore

      - name: Summary
        if: always()
        run: |
          echo "=== Execution Summary ==="
          echo "Workflow: ${{ github.workflow }}"
          echo "Run number: ${{ github.run_number }}"
          echo "Run ID: ${{ github.run_id }}"
          echo "Trigger: ${{ github.event_name }}"
          echo "Crawler result: ${{ steps.crawler.outcome }}"
          echo "Upload result: ${{ steps.upload.outcome }}"
          echo "Records collected: ${{ env.CRAWLED_COUNT }}"
          echo ""
          echo "Artifacts download:"
          echo "${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
